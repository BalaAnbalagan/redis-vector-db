{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1537e6",
   "metadata": {},
   "source": [
    "# Using Redis for Embeddings Search\n",
    "\n",
    "This notebook takes you through a simple flow to download some data, embed it, and then index and search it using a selection of vector databases. This is a common requirement for customers who want to store and search our embeddings with their own data in a secure environment to support production use cases such as chatbots, topic modelling and more.\n",
    "\n",
    "### What is a Vector Database\n",
    "\n",
    "A vector database is a database made to store, manage and search embedding vectors. The use of embeddings to encode unstructured data (text, audio, video and more) as vectors for consumption by machine-learning models has exploded in recent years, due to the increasing effectiveness of AI in solving use cases involving natural language, image recognition and other unstructured forms of data. Vector databases have emerged as an effective solution for enterprises to deliver and scale these use cases.\n",
    "\n",
    "### Why use a Vector Database\n",
    "\n",
    "Vector databases enable enterprises to take many of the embeddings use cases we've shared in this repo (question and answering, chatbot and recommendation services, for example), and make use of them in a secure, scalable environment. Many of our customers make embeddings solve their problems at small scale but performance and security hold them back from going into production - we see vector databases as a key component in solving that, and in this guide we'll walk through the basics of embedding text data, storing it in a vector database and using it for semantic search.\n",
    "\n",
    "\n",
    "### Demo Flow\n",
    "The demo flow is:\n",
    "- **Setup**: Import packages and set any required variables\n",
    "- **Load data**: Load a dataset and embed it using OpenAI embeddings\n",
    "- **Redis**\n",
    "    - *Setup*: Set up the Redis-Py client. For more details go [here](https://github.com/redis/redis-py)\n",
    "    - *Index Data*: Create the search index for vector search and hybrid search (vector + full-text search) on all available fields.\n",
    "    - *Search Data*: Run a few example queries with various goals in mind.\n",
    "\n",
    "Once you've run through this notebook you should have a basic understanding of how to setup and use vector databases, and can move on to more complex use cases making use of our embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b59250",
   "metadata": {},
   "source": "## Setup\n\nImport required libraries and load the OpenAI API key from `redis_config.json`.\n\n<details>\n<summary>üí° <b>What's happening here?</b> (click to expand)</summary>\n\n<br>\n\n**Libraries are like tools:**\n- `pandas` = data tables\n- `numpy` = math operations  \n- `redis` = talk to our database\n- `openai` = create embeddings (convert text to vectors)\n\n**API Key** = Your ID card to use OpenAI's service\n\n**EMBEDDING_MODEL** = `text-embedding-3-small` converts text into 1536 numbers\n\n**Why redis_config.json?** Keeps your secret API key out of the code (secure!)\n\n</details>"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be94df6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T00:02:09.325509Z",
     "iopub.status.busy": "2025-10-29T00:02:09.325341Z",
     "iopub.status.idle": "2025-10-29T00:02:09.805621Z",
     "shell.execute_reply": "2025-10-29T00:02:09.805343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API key loaded from config file\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "from typing import List, Iterator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import wget\n",
    "from ast import literal_eval\n",
    "\n",
    "# Redis client library for Python\n",
    "import redis\n",
    "\n",
    "# Load configuration (including OpenAI API key)\n",
    "import json\n",
    "\n",
    "config_file = 'redis_config.json'\n",
    "if os.path.exists(config_file):\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    # Set OpenAI API key from config file\n",
    "    if 'openai_api_key' in config:\n",
    "        openai.api_key = config['openai_api_key']\n",
    "        print(\"‚úÖ OpenAI API key loaded from config file\")\n",
    "    else:\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "        print(\"‚ö†Ô∏è  OpenAI API key not in config, using environment variable\")\n",
    "else:\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "    print(\"‚ö†Ô∏è  Config file not found, using environment variable for OpenAI key\")\n",
    "\n",
    "# I've set this to our new embeddings model, this can be changed to the embedding model of your choice\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "# Ignore unclosed SSL socket warnings - optional in case you get these errors\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"unclosed\", category=ResourceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d9d2e1",
   "metadata": {},
   "source": "## Load Data\n\nDownload the pre-embedded Wikipedia dataset (25K articles with vectors already computed). We'll use 100 articles to fit within the Redis Cloud free tier constraints (30MB memory + 510 vectors).\n\n<details>\n<summary>üí° <b>What's happening here?</b> (click to expand)</summary>\n\n<br>\n\n**The Dataset:**\n- 25,000 Wikipedia articles\n- Each article already has vectors (1536 numbers representing meaning)\n- Pre-embedded = saves time and money!\n\n**Why only 100 articles?**\n- Redis Cloud free tier has 2 limits:\n  - 30MB memory limit\n  - 510 vectors per index limit\n- We use 100 to comfortably fit both constraints\n- Still enough to learn all vector database concepts!\n\n**Vectors = Meaning:**\n- Articles are represented as coordinates in 1536-dimensional space\n- Similar articles = close together in this space\n- Like comparing \"summary cards\" instead of reading entire books\n\n</details>"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dff8b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T00:02:09.806850Z",
     "iopub.status.busy": "2025-10-29T00:02:09.806736Z",
     "iopub.status.idle": "2025-10-29T00:02:16.003822Z",
     "shell.execute_reply": "2025-10-29T00:02:16.003535Z"
    }
   },
   "outputs": [],
   "source": "# Step 1: Download the pre-embedded Wikipedia dataset (~700MB) - only if not already downloaded\nembeddings_url = 'https://cdn.openai.com/API/examples/data/vector_database_wikipedia_articles_embedded.zip'\nzip_file = \"vector_database_wikipedia_articles_embedded.zip\"\ncsv_file = \"../data/vector_database_wikipedia_articles_embedded.csv\"\n\nif os.path.exists(csv_file):\n    print(f\"‚úÖ Data already exists at {csv_file} - skipping download\")\nelif os.path.exists(zip_file):\n    print(f\"‚úÖ Zip file already exists - skipping download\")\nelse:\n    print(\"üì• Downloading dataset (this may take a few minutes)...\")\n    wget.download(embeddings_url)\n    print(\"\\n‚úÖ Download complete!\")\n\n# Step 2: Extract the zip file (only if CSV doesn't exist)\nif not os.path.exists(csv_file):\n    if os.path.exists(zip_file):\n        print(\"\\nüì¶ Extracting files...\")\n        import zipfile\n        with zipfile.ZipFile(zip_file, \"r\") as zip_ref:\n            zip_ref.extractall(\"../data\")\n        print(\"‚úÖ Files extracted to ../data/\")\n    else:\n        print(\"‚ùå Zip file not found - please check download\")\nelse:\n    print(\"‚úÖ CSV already extracted - skipping extraction\")\n\n# Step 3: Load the CSV into a pandas DataFrame\nprint(\"\\nüìä Loading data into DataFrame...\")\narticle_df = pd.read_csv(csv_file)\nprint(f\"‚úÖ Loaded {len(article_df)} articles\")\n\n# Step 4: Preview the data\nprint(\"\\nüëÄ First 5 articles:\")\ndisplay(article_df.head())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b82af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T00:02:27.080800Z",
     "iopub.status.busy": "2025-10-29T00:02:27.080666Z",
     "iopub.status.idle": "2025-10-29T00:06:30.637122Z",
     "shell.execute_reply": "2025-10-29T00:06:30.636801Z"
    }
   },
   "outputs": [],
   "source": "# Step 5: Prepare the vectors for Redis\nprint(\"\\nüîß Preparing vectors...\")\n\n# Convert vector strings to actual Python lists\n# They're currently stored as text like \"[0.1, 0.2, ...]\" and need to be real lists\narticle_df['title_vector'] = article_df.title_vector.apply(literal_eval)\narticle_df['content_vector'] = article_df.content_vector.apply(literal_eval)\n\n# Convert vector_id to string (Redis expects string keys)\narticle_df['vector_id'] = article_df['vector_id'].apply(str)\n\n# Step 6: Reduce dataset for Redis Cloud Free Tier\n# Free tier has both memory (30MB) and vector (510) limits\n# We'll use 100 articles to comfortably fit within both constraints\nprint(f\"üìö Full dataset size: {len(article_df)} articles\")\narticle_df = article_df.head(100)  # Use 100 articles\nprint(f\"‚úÖ Using {len(article_df)} articles (fits in Redis Cloud free tier)\")\nprint(f\"üí° Free tier: 30MB memory + 510 vector limit - using 100 articles to stay safe\")\n\n# Step 7: Show dataset info\nprint(\"\\nüìã Dataset Information:\")\narticle_df.info(show_counts=True)"
  },
  {
   "cell_type": "markdown",
   "id": "43bffd04",
   "metadata": {},
   "source": [
    "# Redis\n",
    "\n",
    "The next vector database covered in this tutorial is **[Redis](https://redis.io)**. You most likely already know Redis. What you might not be aware of is the [RediSearch module](https://github.com/RediSearch/RediSearch). Enterprises have been using Redis with the RediSearch module for years now across all major cloud providers, Redis Cloud, and on premise. Recently, the Redis team added vector storage and search capability to this module in addition to the features RediSearch already had.\n",
    "\n",
    "Given the large ecosystem around Redis, there are most likely client libraries in the language you need. You can use any standard Redis client library to run RediSearch commands, but it's easiest to use a library that wraps the RediSearch API. Below are a few examples, but you can find more client libraries [here](https://redis.io/resources/clients/).\n",
    "\n",
    "| Project | Language | License | Author | Stars |\n",
    "|----------|---------|--------|---------|-------|\n",
    "| [jedis][jedis-url] | Java | MIT | [Redis][redis-url] | ![Stars][jedis-stars] |\n",
    "| [redis-py][redis-py-url] | Python | MIT | [Redis][redis-url] | ![Stars][redis-py-stars] |\n",
    "| [node-redis][node-redis-url] | Node.js | MIT | [Redis][redis-url] | ![Stars][node-redis-stars] |\n",
    "| [nredisstack][nredisstack-url] | .NET | MIT | [Redis][redis-url] | ![Stars][nredisstack-stars] |\n",
    "| [redisearch-go][redisearch-go-url] | Go | BSD | [Redis][redisearch-go-author] | [![redisearch-go-stars]][redisearch-go-url] |\n",
    "| [redisearch-api-rs][redisearch-api-rs-url] | Rust | BSD | [Redis][redisearch-api-rs-author] | [![redisearch-api-rs-stars]][redisearch-api-rs-url] |\n",
    "\n",
    "[redis-url]: https://redis.com\n",
    "\n",
    "[redis-py-url]: https://github.com/redis/redis-py\n",
    "[redis-py-stars]: https://img.shields.io/github/stars/redis/redis-py.svg?style=social&amp;label=Star&amp;maxAge=2592000\n",
    "[redis-py-package]: https://pypi.python.org/pypi/redis\n",
    "\n",
    "[jedis-url]: https://github.com/redis/jedis\n",
    "[jedis-stars]: https://img.shields.io/github/stars/redis/jedis.svg?style=social&amp;label=Star&amp;maxAge=2592000\n",
    "[Jedis-package]: https://search.maven.org/artifact/redis.clients/jedis\n",
    "\n",
    "[nredisstack-url]: https://github.com/redis/nredisstack\n",
    "[nredisstack-stars]: https://img.shields.io/github/stars/redis/nredisstack.svg?style=social&amp;label=Star&amp;maxAge=2592000\n",
    "[nredisstack-package]: https://www.nuget.org/packages/nredisstack/\n",
    "\n",
    "[node-redis-url]: https://github.com/redis/node-redis\n",
    "[node-redis-stars]: https://img.shields.io/github/stars/redis/node-redis.svg?style=social&amp;label=Star&amp;maxAge=2592000\n",
    "[node-redis-package]: https://www.npmjs.com/package/redis\n",
    "\n",
    "[redis-om-python-url]: https://github.com/redis/redis-om-python\n",
    "[redis-om-python-author]: https://redis.com\n",
    "[redis-om-python-stars]: https://img.shields.io/github/stars/redis/redis-om-python.svg?style=social&amp;label=Star&amp;maxAge=2592000\n",
    "\n",
    "[redisearch-go-url]: https://github.com/RediSearch/redisearch-go\n",
    "[redisearch-go-author]: https://redis.com\n",
    "[redisearch-go-stars]: https://img.shields.io/github/stars/RediSearch/redisearch-go.svg?style=social&amp;label=Star&amp;maxAge=2592000\n",
    "\n",
    "[redisearch-api-rs-url]: https://github.com/RediSearch/redisearch-api-rs\n",
    "[redisearch-api-rs-author]: https://redis.com\n",
    "[redisearch-api-rs-stars]: https://img.shields.io/github/stars/RediSearch/redisearch-api-rs.svg?style=social&amp;label=Star&amp;maxAge=2592000\n",
    "\n",
    "\n",
    "In the below cells, we will walk you through using Redis as a vector database. Since many of you are likely already used to the Redis API, this should be familiar to most."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e24f6",
   "metadata": {},
   "source": "## Connect to Redis\n\nLoad credentials from `redis_config.json` and establish connection to Redis Cloud.\n\n<details>\n<summary>üí° <b>What's happening here?</b> (click to expand)</summary>\n\n<br>\n\n**Redis + RediSearch = Vector Database**\n\nRegular Redis is just a fast key-value store, but with the RediSearch module it can:\n- Store vectors efficiently\n- Search by similarity (not just exact matches)\n- Handle hybrid queries (vector + text filters)\n\n**What we're doing:**\n1. Load credentials (host, port, password) from config file\n2. Connect to Redis Cloud \n3. Test connection with `ping()`\n\n**Redis Cloud** = Managed service (like Gmail vs. running your own email server)\n\n</details>"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2ce669a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T00:06:30.650204Z",
     "iopub.status.busy": "2025-10-29T00:06:30.650122Z",
     "iopub.status.idle": "2025-10-29T00:06:30.722053Z",
     "shell.execute_reply": "2025-10-29T00:06:30.721755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded config from redis_config.json\n",
      "Testing Redis connection...\n",
      "‚úÖ Connected to Redis! Response: True\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "from redis.commands.search.indexDefinition import (\n",
    "    IndexDefinition,\n",
    "    IndexType\n",
    ")\n",
    "from redis.commands.search.query import Query\n",
    "from redis.commands.search.field import (\n",
    "    TextField,\n",
    "    VectorField\n",
    ")\n",
    "\n",
    "# Load Redis connection details from config file\n",
    "import json\n",
    "import os\n",
    "\n",
    "config_file = 'redis_config.json'\n",
    "if os.path.exists(config_file):\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    REDIS_HOST = config['redis_host']\n",
    "    REDIS_PORT = config['redis_port']\n",
    "    REDIS_PASSWORD = config['redis_password']\n",
    "    print(f\"‚úÖ Loaded config from {config_file}\")\n",
    "else:\n",
    "    # Fallback to environment variables or localhost\n",
    "    REDIS_HOST = os.getenv('REDIS_HOST', 'localhost')\n",
    "    REDIS_PORT = int(os.getenv('REDIS_PORT', 6379))\n",
    "    REDIS_PASSWORD = os.getenv('REDIS_PASSWORD', '')\n",
    "    print(f\"‚ö†Ô∏è  Config file not found. Using environment variables or defaults.\")\n",
    "    print(f\"   Create {config_file} with your Redis Cloud credentials.\")\n",
    "\n",
    "# Connect to Redis\n",
    "redis_client = redis.Redis(\n",
    "    host=REDIS_HOST,\n",
    "    port=REDIS_PORT,\n",
    "    password=REDIS_PASSWORD\n",
    ")\n",
    "print(\"Testing Redis connection...\")\n",
    "response = redis_client.ping()\n",
    "print(f\"‚úÖ Connected to Redis! Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kpjkygjth8p",
   "source": "## Health Check & Cleanup (Optional)\n\nCheck database status and optionally cleanup before proceeding. Useful when re-running the notebook.\n\nRun `check_redis_health(redis_client)` to see current state, or `cleanup_redis(redis_client, 'index_and_docs')` to start fresh.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "vm01otahbqe",
   "source": "from IPython.display import display, HTML, Markdown\n\ndef check_redis_health(client: redis.Redis) -> dict:\n    \"\"\"\n    Comprehensive Redis database health check with rich visual output.\n    Returns a dictionary with health metrics and status.\n    \"\"\"\n    health_status = {\n        \"connection\": False,\n        \"memory_usage_mb\": 0,\n        \"total_keys\": 0,\n        \"indices\": [],\n        \"doc_keys\": 0,\n        \"memory_percent\": 0,\n        \"warnings\": []\n    }\n    \n    # Header\n    display(HTML(\"\"\"\n    <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n                padding: 20px; border-radius: 10px; margin: 10px 0;'>\n        <h2 style='color: white; margin: 0; text-align: center;'>\n            üè• REDIS DATABASE HEALTH CHECK\n        </h2>\n    </div>\n    \"\"\"))\n    \n    try:\n        # Test connection\n        client.ping()\n        health_status[\"connection\"] = True\n        display(HTML(\"<div style='color: #10b981; font-weight: bold; font-size: 16px;'>‚úÖ Redis connection is healthy</div>\"))\n        \n        # Get server info\n        info = client.info()\n        memory_used = info.get('used_memory', 0) / (1024 * 1024)  # Convert to MB\n        health_status[\"memory_usage_mb\"] = round(memory_used, 2)\n        \n        # Get total keys\n        for db_key in info.keys():\n            if db_key.startswith('db'):\n                health_status[\"total_keys\"] += info[db_key].get('keys', 0)\n        \n        # Display metrics in styled boxes\n        display(HTML(f\"\"\"\n        <div style='display: flex; gap: 15px; margin: 20px 0; flex-wrap: wrap;'>\n            <div style='background: #f0f9ff; border-left: 4px solid #3b82f6; \n                        padding: 15px; border-radius: 5px; flex: 1; min-width: 200px;'>\n                <div style='color: #3b82f6; font-size: 24px;'>üìä</div>\n                <div style='font-size: 14px; color: #64748b; margin-top: 5px;'>Memory Usage</div>\n                <div style='font-size: 24px; font-weight: bold; color: #1e293b;'>{health_status['memory_usage_mb']} MB</div>\n            </div>\n            <div style='background: #fef3c7; border-left: 4px solid #f59e0b; \n                        padding: 15px; border-radius: 5px; flex: 1; min-width: 200px;'>\n                <div style='color: #f59e0b; font-size: 24px;'>üîë</div>\n                <div style='font-size: 14px; color: #64748b; margin-top: 5px;'>Total Keys</div>\n                <div style='font-size: 24px; font-weight: bold; color: #1e293b;'>{health_status['total_keys']}</div>\n            </div>\n        </div>\n        \"\"\"))\n        \n        # Check for existing indices\n        try:\n            indices = []\n            # Try to get info on our specific index\n            try:\n                index_info = client.ft(\"embeddings-index\").info()\n                indices.append(\"embeddings-index\")\n                index_docs = index_info.get('num_docs', 0)\n                display(HTML(f\"\"\"\n                <div style='background: #dcfce7; border-left: 4px solid #10b981; \n                            padding: 15px; border-radius: 5px; margin: 10px 0;'>\n                    <div style='color: #10b981; font-weight: bold;'>\n                        üìá Index 'embeddings-index' exists with {index_docs} documents\n                    </div>\n                </div>\n                \"\"\"))\n            except:\n                display(HTML(\"\"\"\n                <div style='background: #f3f4f6; border-left: 4px solid #6b7280; \n                            padding: 15px; border-radius: 5px; margin: 10px 0;'>\n                    <div style='color: #6b7280;'>\n                        üìá Index 'embeddings-index' does not exist (will be created)\n                    </div>\n                </div>\n                \"\"\"))\n            \n            health_status[\"indices\"] = indices\n        except Exception as e:\n            print(f\"‚ö†Ô∏è  Could not check indices: {e}\")\n        \n        # Count document keys with our prefix\n        doc_count = 0\n        for key in client.scan_iter(\"doc:*\"):\n            doc_count += 1\n            if doc_count >= 10:  # Sample only first 10 for performance\n                # Get total count properly\n                doc_count = len(list(client.scan_iter(\"doc:*\")))\n                break\n        \n        health_status[\"doc_keys\"] = doc_count\n        if doc_count > 0:\n            display(HTML(f\"\"\"\n            <div style='background: #e0e7ff; border-left: 4px solid #6366f1; \n                        padding: 15px; border-radius: 5px; margin: 10px 0;'>\n                <div style='color: #6366f1; font-weight: bold;'>\n                    üìÑ Found {doc_count} document keys with prefix 'doc:'\n                </div>\n            </div>\n            \"\"\"))\n        \n        # Check memory usage percentage (assuming 30MB free tier limit)\n        FREE_TIER_LIMIT_MB = 30\n        memory_percent = (memory_used / FREE_TIER_LIMIT_MB) * 100\n        health_status[\"memory_percent\"] = round(memory_percent, 1)\n        \n        # Memory usage gauge\n        if memory_percent > 90:\n            color = \"#ef4444\"\n            bg_color = \"#fee2e2\"\n            icon = \"‚ö†Ô∏è\"\n            message = f\"WARNING: Using {memory_percent}% of free tier limit (30MB)\"\n            health_status[\"warnings\"].append(message)\n        elif memory_percent > 70:\n            color = \"#f59e0b\"\n            bg_color = \"#fef3c7\"\n            icon = \"‚ö†Ô∏è\"\n            message = f\"NOTICE: Using {memory_percent}% of free tier limit\"\n            health_status[\"warnings\"].append(message)\n        else:\n            color = \"#10b981\"\n            bg_color = \"#dcfce7\"\n            icon = \"‚úÖ\"\n            message = f\"Memory usage is healthy ({memory_percent}% of 30MB free tier)\"\n        \n        display(HTML(f\"\"\"\n        <div style='background: {bg_color}; border-left: 4px solid {color}; \n                    padding: 15px; border-radius: 5px; margin: 15px 0;'>\n            <div style='color: {color}; font-weight: bold; font-size: 16px;'>\n                {icon} {message}\n            </div>\n            <div style='background: #e5e7eb; border-radius: 10px; height: 20px; \n                        margin-top: 10px; overflow: hidden;'>\n                <div style='background: {color}; height: 100%; width: {memory_percent}%; \n                            transition: width 0.3s ease;'></div>\n            </div>\n        </div>\n        \"\"\"))\n        \n    except redis.exceptions.ConnectionError as e:\n        health_status[\"connection\"] = False\n        health_status[\"warnings\"].append(f\"Connection Error: {e}\")\n        display(HTML(f\"\"\"\n        <div style='background: #fee2e2; border-left: 4px solid #ef4444; \n                    padding: 15px; border-radius: 5px; margin: 10px 0;'>\n            <div style='color: #ef4444; font-weight: bold;'>\n                ‚ùå Redis connection failed: {e}\n            </div>\n        </div>\n        \"\"\"))\n    except Exception as e:\n        health_status[\"warnings\"].append(f\"Health check error: {e}\")\n        display(HTML(f\"\"\"\n        <div style='background: #fef3c7; border-left: 4px solid #f59e0b; \n                    padding: 15px; border-radius: 5px; margin: 10px 0;'>\n            <div style='color: #f59e0b; font-weight: bold;'>\n                ‚ö†Ô∏è  Error during health check: {e}\n            </div>\n        </div>\n        \"\"\"))\n    \n    return health_status\n\n\ndef cleanup_redis(client: redis.Redis, cleanup_type: str = \"all\"):\n    \"\"\"\n    Clean up Redis database with rich visual feedback.\n    \n    Args:\n        client: Redis client instance\n        cleanup_type: Type of cleanup to perform\n            - \"all\": Delete all keys (FLUSHDB)\n            - \"index\": Delete only the search index\n            - \"docs\": Delete only document keys (doc:*)\n            - \"index_and_docs\": Delete index and document keys\n    \"\"\"\n    display(HTML(f\"\"\"\n    <div style='background: linear-gradient(135deg, #f59e0b 0%, #dc2626 100%); \n                padding: 15px; border-radius: 10px; margin: 10px 0;'>\n        <h3 style='color: white; margin: 0;'>üßπ Starting Cleanup: {cleanup_type}</h3>\n    </div>\n    \"\"\"))\n    \n    try:\n        if cleanup_type == \"all\":\n            # Nuclear option - delete everything\n            confirm = input(\"‚ö†Ô∏è  This will delete ALL data in the database. Type 'YES' to confirm: \")\n            if confirm == \"YES\":\n                client.flushdb()\n                display(HTML(\"\"\"\n                <div style='background: #dcfce7; border-left: 4px solid #10b981; \n                            padding: 15px; border-radius: 5px; margin: 10px 0;'>\n                    <div style='color: #10b981; font-weight: bold;'>\n                        ‚úÖ Database flushed completely\n                    </div>\n                </div>\n                \"\"\"))\n            else:\n                display(HTML(\"\"\"\n                <div style='background: #f3f4f6; border-left: 4px solid #6b7280; \n                            padding: 15px; border-radius: 5px; margin: 10px 0;'>\n                    <div style='color: #6b7280;'>‚ùå Cleanup cancelled</div>\n                </div>\n                \"\"\"))\n                return\n        \n        elif cleanup_type == \"index\":\n            # Delete only the search index\n            try:\n                client.ft(\"embeddings-index\").dropindex(delete_documents=False)\n                display(HTML(\"\"\"\n                <div style='background: #dcfce7; border-left: 4px solid #10b981; \n                            padding: 15px; border-radius: 5px; margin: 10px 0;'>\n                    <div style='color: #10b981; font-weight: bold;'>\n                        ‚úÖ Search index 'embeddings-index' deleted (documents preserved)\n                    </div>\n                </div>\n                \"\"\"))\n            except Exception as e:\n                display(HTML(f\"\"\"\n                <div style='background: #fef3c7; border-left: 4px solid #f59e0b; \n                            padding: 15px; border-radius: 5px; margin: 10px 0;'>\n                    <div style='color: #f59e0b;'>\n                        ‚ö†Ô∏è  Could not delete index (may not exist): {e}\n                    </div>\n                </div>\n                \"\"\"))\n        \n        elif cleanup_type == \"docs\":\n            # Delete only document keys\n            doc_keys = list(client.scan_iter(\"doc:*\"))\n            if doc_keys:\n                count = len(doc_keys)\n                confirm = input(f\"‚ö†Ô∏è  This will delete {count} document keys. Type 'YES' to confirm: \")\n                if confirm == \"YES\":\n                    for key in doc_keys:\n                        client.delete(key)\n                    display(HTML(f\"\"\"\n                    <div style='background: #dcfce7; border-left: 4px solid #10b981; \n                                padding: 15px; border-radius: 5px; margin: 10px 0;'>\n                        <div style='color: #10b981; font-weight: bold;'>\n                            ‚úÖ Deleted {count} document keys\n                        </div>\n                    </div>\n                    \"\"\"))\n                else:\n                    display(HTML(\"\"\"\n                    <div style='background: #f3f4f6; border-left: 4px solid #6b7280; \n                                padding: 15px; border-radius: 5px; margin: 10px 0;'>\n                        <div style='color: #6b7280;'>‚ùå Cleanup cancelled</div>\n                    </div>\n                    \"\"\"))\n            else:\n                display(HTML(\"\"\"\n                <div style='background: #e0e7ff; border-left: 4px solid #6366f1; \n                            padding: 15px; border-radius: 5px; margin: 10px 0;'>\n                    <div style='color: #6366f1;'>‚ÑπÔ∏è  No document keys found</div>\n                </div>\n                \"\"\"))\n        \n        elif cleanup_type == \"index_and_docs\":\n            # Delete index AND documents\n            try:\n                client.ft(\"embeddings-index\").dropindex(delete_documents=True)\n                display(HTML(\"\"\"\n                <div style='background: #dcfce7; border-left: 4px solid #10b981; \n                            padding: 15px; border-radius: 5px; margin: 10px 0;'>\n                    <div style='color: #10b981; font-weight: bold;'>\n                        ‚úÖ Search index 'embeddings-index' and all documents deleted\n                    </div>\n                </div>\n                \"\"\"))\n            except Exception as e:\n                display(HTML(f\"\"\"\n                <div style='background: #fef3c7; border-left: 4px solid #f59e0b; \n                            padding: 15px; border-radius: 5px; margin: 10px 0;'>\n                    <div style='color: #f59e0b;'>\n                        ‚ö†Ô∏è  Could not delete index: {e}\n                    </div>\n                </div>\n                \"\"\"))\n                # Try to delete docs manually as fallback\n                doc_keys = list(client.scan_iter(\"doc:*\"))\n                if doc_keys:\n                    for key in doc_keys:\n                        client.delete(key)\n                    display(HTML(f\"\"\"\n                    <div style='background: #dcfce7; border-left: 4px solid #10b981; \n                                padding: 15px; border-radius: 5px; margin: 10px 0;'>\n                        <div style='color: #10b981; font-weight: bold;'>\n                            ‚úÖ Deleted {len(doc_keys)} document keys manually\n                        </div>\n                    </div>\n                    \"\"\"))\n        \n        else:\n            display(HTML(f\"\"\"\n            <div style='background: #fee2e2; border-left: 4px solid #ef4444; \n                        padding: 15px; border-radius: 5px; margin: 10px 0;'>\n                <div style='color: #ef4444; font-weight: bold;'>\n                    ‚ùå Invalid cleanup type: {cleanup_type}\n                </div>\n                <div style='color: #64748b; margin-top: 10px;'>\n                    Valid options: 'all', 'index', 'docs', 'index_and_docs'\n                </div>\n            </div>\n            \"\"\"))\n        \n        # Show updated status\n        display(HTML(\"\"\"\n        <div style='background: #f8fafc; padding: 15px; border-radius: 10px; margin: 20px 0;'>\n            <h4 style='color: #475569; margin-top: 0;'>üìä Updated Database Status:</h4>\n        </div>\n        \"\"\"))\n        check_redis_health(client)\n        \n    except Exception as e:\n        display(HTML(f\"\"\"\n        <div style='background: #fee2e2; border-left: 4px solid #ef4444; \n                    padding: 15px; border-radius: 5px; margin: 10px 0;'>\n            <div style='color: #ef4444; font-weight: bold;'>\n                ‚ùå Error during cleanup: {e}\n            </div>\n        </div>\n        \"\"\"))\n\n\n# Display instructions\ndisplay(HTML(\"\"\"\n<div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n            padding: 20px; border-radius: 10px; margin: 20px 0;'>\n    <h3 style='color: white; margin-top: 0;'>üîß Health Check & Cleanup Functions Loaded</h3>\n    <div style='background: rgba(255,255,255,0.1); padding: 15px; border-radius: 5px; \n                color: white;'>\n        <p style='margin: 5px 0;'>‚úÖ Functions are now available. Run one of these commands:</p>\n    </div>\n    <div style='background: rgba(255,255,255,0.1); padding: 15px; border-radius: 5px; \n                color: white; font-family: monospace; margin-top: 10px;'>\n        <div style='margin: 10px 0;'><strong style='color: #fbbf24;'>check_redis_health(redis_client)</strong> \n            <span style='opacity: 0.8;'># Check database status</span></div>\n    </div>\n    <div style='background: rgba(255,255,255,0.2); padding: 10px; border-radius: 5px; \n                margin-top: 15px; color: white;'>\n        <strong>üí° Cleanup Options:</strong>\n    </div>\n    <div style='background: rgba(255,255,255,0.1); padding: 15px; border-radius: 5px; \n                color: white; font-family: monospace; margin-top: 5px;'>\n        <div style='margin: 5px 0;'><strong>cleanup_redis(redis_client, 'index_and_docs')</strong> \n            <span style='opacity: 0.8;'># ‚≠ê Clean slate</span></div>\n        <div style='margin: 5px 0;'><strong>cleanup_redis(redis_client, 'index')</strong> \n            <span style='opacity: 0.8;'># Delete index only</span></div>\n        <div style='margin: 5px 0;'><strong>cleanup_redis(redis_client, 'docs')</strong> \n            <span style='opacity: 0.8;'># Delete docs only</span></div>\n        <div style='margin: 5px 0;'><strong>cleanup_redis(redis_client, 'all')</strong> \n            <span style='opacity: 0.8;'># ‚ö†Ô∏è Nuclear option</span></div>\n    </div>\n</div>\n\"\"\"))\n\nprint(\"‚úÖ Health check and cleanup functions ready!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3f6f0af9",
   "metadata": {},
   "source": "## Create Search Index\n\nDefine the schema and create a RediSearch index for vector similarity search using COSINE distance on 1536-dimensional embeddings."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c64cb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T00:06:30.723340Z",
     "iopub.status.busy": "2025-10-29T00:06:30.723254Z",
     "iopub.status.idle": "2025-10-29T00:06:30.725264Z",
     "shell.execute_reply": "2025-10-29T00:06:30.725011Z"
    }
   },
   "outputs": [],
   "source": "# Import RediSearch classes for index creation\nfrom redis.commands.search.indexDefinition import IndexDefinition, IndexType\nfrom redis.commands.search.field import TextField, VectorField\n\n# Step 1: Define constants for our index\nprint(\"üìã Setting up index parameters...\")\n\nVECTOR_DIM = len(article_df['title_vector'][0])  # length of the vectors (1536)\nVECTOR_NUMBER = len(article_df)                   # initial number of vectors (2500)\nINDEX_NAME = \"embeddings-index\"                   # name of the search index\nPREFIX = \"doc\"                                    # prefix for the document keys\nDISTANCE_METRIC = \"COSINE\"                        # distance metric for the vectors\n\nprint(f\"  Vector dimensions: {VECTOR_DIM}\")\nprint(f\"  Number of vectors: {VECTOR_NUMBER}\")\nprint(f\"  Index name: {INDEX_NAME}\")\nprint(f\"  Distance metric: {DISTANCE_METRIC}\")\n\n# Step 2: Define the schema (what fields exist and how to index them)\nprint(\"\\nüèóÔ∏è  Defining index schema...\")\n\n# Text fields (can be searched with keywords)\ntitle = TextField(name=\"title\")\nurl = TextField(name=\"url\")\ntext = TextField(name=\"text\")\n\n# Vector fields (can be searched by similarity)\ntitle_embedding = VectorField(\"title_vector\",\n    \"FLAT\", {\n        \"TYPE\": \"FLOAT32\",\n        \"DIM\": VECTOR_DIM,\n        \"DISTANCE_METRIC\": DISTANCE_METRIC,\n        \"INITIAL_CAP\": VECTOR_NUMBER,\n    }\n)\ntext_embedding = VectorField(\"content_vector\",\n    \"FLAT\", {\n        \"TYPE\": \"FLOAT32\",\n        \"DIM\": VECTOR_DIM,\n        \"DISTANCE_METRIC\": DISTANCE_METRIC,\n        \"INITIAL_CAP\": VECTOR_NUMBER,\n    }\n)\n\nfields = [title, url, text, title_embedding, text_embedding]\nprint(f\"  Defined {len(fields)} fields (3 text + 2 vector)\")\n\n# Step 3: Create the index (or check if it already exists)\nprint(\"\\nüî® Creating search index...\")\ntry:\n    redis_client.ft(INDEX_NAME).info()\n    print(f\"‚ö†Ô∏è  Index '{INDEX_NAME}' already exists - skipping creation\")\n    print(\"   üí° Run cleanup_redis(redis_client, 'index_and_docs') to start fresh\")\nexcept:\n    # Create RediSearch Index\n    redis_client.ft(INDEX_NAME).create_index(\n        fields = fields,\n        definition = IndexDefinition(prefix=[PREFIX], index_type=IndexType.HASH)\n    )\n    print(f\"‚úÖ Index '{INDEX_NAME}' created successfully!\")"
  },
  {
   "cell_type": "markdown",
   "id": "f3563eec",
   "metadata": {},
   "source": "## Load Documents into Index\n\nConvert vectors to binary format and load all 100 documents into Redis. Takes ~5 seconds.\n\n<details>\n<summary>üí° <b>What's happening here?</b> (click to expand)</summary>\n\n<br>\n\n**What we're doing:**\n1. Loop through all 100 Wikipedia articles\n2. Convert vectors from Python lists ‚Üí binary bytes (Redis storage format)\n3. Store each article as a HASH in Redis with key `doc:1`, `doc:2`, etc.\n\n**Why convert to bytes?**\n- Redis stores binary data more efficiently than text\n- A list of 1536 floats as text \"[0.1, 0.2, ...]\" takes more space than binary bytes\n\n**HASH data type** = Like a Python dictionary in Redis:\n```\ndoc:1 ‚Üí {title: \"April\", text: \"April is...\", title_vector: <binary>, ...}\n```\n\n</details>"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d63ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T00:06:31.511500Z",
     "iopub.status.busy": "2025-10-29T00:06:31.511402Z",
     "iopub.status.idle": "2025-10-29T00:06:31.513864Z",
     "shell.execute_reply": "2025-10-29T00:06:31.513595Z"
    }
   },
   "outputs": [],
   "source": "# Define function to load documents into Redis\ndef index_documents(client: redis.Redis, prefix: str, documents: pd.DataFrame):\n    \"\"\"\n    Load a pandas DataFrame of documents into Redis.\n    \n    Args:\n        client: Redis client connection\n        prefix: Prefix for document keys (e.g., 'doc' creates 'doc:1', 'doc:2', ...)\n        documents: DataFrame with columns including vectors\n    \"\"\"\n    records = documents.to_dict(\"records\")\n    total = len(records)\n    \n    print(f\"üìù Loading {total} documents into Redis...\")\n    \n    for i, doc in enumerate(records):\n        # Create unique key for this document\n        key = f\"{prefix}:{str(doc['id'])}\"\n\n        # Convert vectors from Python lists to binary format\n        # Redis stores bytes more efficiently than text representations\n        title_embedding = np.array(doc[\"title_vector\"], dtype=np.float32).tobytes()\n        content_embedding = np.array(doc[\"content_vector\"], dtype=np.float32).tobytes()\n\n        # Replace list of floats with byte vectors\n        doc[\"title_vector\"] = title_embedding\n        doc[\"content_vector\"] = content_embedding\n\n        # Store document as a HASH in Redis\n        client.hset(key, mapping = doc)\n        \n        # Progress indicator every 500 documents\n        if (i + 1) % 500 == 0:\n            print(f\"  ‚úì Loaded {i + 1}/{total} documents...\")\n    \n    print(f\"‚úÖ All {total} documents loaded successfully!\")\n\n# Execute the loading\nindex_documents(redis_client, PREFIX, article_df)\n\n# Verify the load\ninfo = redis_client.info()\ntotal_keys = info.get('db0', {}).get('keys', 0)\nprint(f\"\\nüìä Final status: {total_keys} total keys in Redis\")\nprint(f\"   Index name: {INDEX_NAME}\")"
  },
  {
   "cell_type": "markdown",
   "id": "f646bff4",
   "metadata": {},
   "source": "## Semantic Search\n\nSearch by meaning, not just keywords. Query text is converted to a vector and matched against stored documents using K-Nearest Neighbors (KNN)."
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "508d1f89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T00:06:43.220467Z",
     "iopub.status.busy": "2025-10-29T00:06:43.220366Z",
     "iopub.status.idle": "2025-10-29T00:06:43.223566Z",
     "shell.execute_reply": "2025-10-29T00:06:43.223283Z"
    }
   },
   "outputs": [],
   "source": [
    "def search_redis(\n",
    "    redis_client: redis.Redis,\n",
    "    user_query: str,\n",
    "    index_name: str = \"embeddings-index\",\n",
    "    vector_field: str = \"title_vector\",\n",
    "    return_fields: list = [\"title\", \"url\", \"text\", \"vector_score\"],\n",
    "    hybrid_fields = \"*\",\n",
    "    k: int = 20,\n",
    ") -> List[dict]:\n",
    "\n",
    "    # Creates embedding vector from user query\n",
    "    embedded_query = openai.Embedding.create(input=user_query,\n",
    "                                            model=EMBEDDING_MODEL,\n",
    "                                            )[\"data\"][0]['embedding']\n",
    "\n",
    "    # Prepare the Query\n",
    "    base_query = f'{hybrid_fields}=>[KNN {k} @{vector_field} $vector AS vector_score]'\n",
    "    query = (\n",
    "        Query(base_query)\n",
    "         .return_fields(*return_fields)\n",
    "         .sort_by(\"vector_score\")\n",
    "         .paging(0, k)\n",
    "         .dialect(2)\n",
    "    )\n",
    "    params_dict = {\"vector\": np.array(embedded_query).astype(dtype=np.float32).tobytes()}\n",
    "\n",
    "    # perform vector search\n",
    "    results = redis_client.ft(index_name).search(query, params_dict)\n",
    "    for i, article in enumerate(results.docs):\n",
    "        score = 1 - float(article.vector_score)\n",
    "        print(f\"{i}. {article.title} (Score: {round(score ,3) })\")\n",
    "    return results.docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f0eef07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T00:06:43.224617Z",
     "iopub.status.busy": "2025-10-29T00:06:43.224557Z",
     "iopub.status.idle": "2025-10-29T00:06:43.245116Z",
     "shell.execute_reply": "2025-10-29T00:06:43.244772Z"
    }
   },
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# OpenAI API key is already set from config file in the setup cell above\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# If you need to override it, you can uncomment the line below:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"your-key-here\")\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msearch_redis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mredis_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodern art in Europe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m, in \u001b[0;36msearch_redis\u001b[0;34m(redis_client, user_query, index_name, vector_field, return_fields, hybrid_fields, k)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch_redis\u001b[39m(\n\u001b[1;32m      2\u001b[0m     redis_client: redis\u001b[38;5;241m.\u001b[39mRedis,\n\u001b[1;32m      3\u001b[0m     user_query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Creates embedding vector from user query\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     embedded_query \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEMBEDDING_MODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Prepare the Query\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     base_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhybrid_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=>[KNN \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m @\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvector_field\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m $vector AS vector_score]\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "# OpenAI API key is already set from config file in the setup cell above\n",
    "# If you need to override it, you can uncomment the line below:\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"your-key-here\")\n",
    "\n",
    "results = search_redis(redis_client, 'modern art in Europe', k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b805a81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T00:06:43.246657Z",
     "iopub.status.busy": "2025-10-29T00:06:43.246560Z",
     "iopub.status.idle": "2025-10-29T00:06:43.260276Z",
     "shell.execute_reply": "2025-10-29T00:06:43.259987Z"
    }
   },
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msearch_redis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mredis_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFamous battles in Scottish history\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent_vector\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m, in \u001b[0;36msearch_redis\u001b[0;34m(redis_client, user_query, index_name, vector_field, return_fields, hybrid_fields, k)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch_redis\u001b[39m(\n\u001b[1;32m      2\u001b[0m     redis_client: redis\u001b[38;5;241m.\u001b[39mRedis,\n\u001b[1;32m      3\u001b[0m     user_query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Creates embedding vector from user query\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     embedded_query \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEMBEDDING_MODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Prepare the Query\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     base_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhybrid_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=>[KNN \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m @\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvector_field\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m $vector AS vector_score]\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "results = search_redis(redis_client, 'Famous battles in Scottish history', vector_field='content_vector', k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed0b34e",
   "metadata": {},
   "source": [
    "## Hybrid Queries with Redis\n",
    "\n",
    "The previous examples showed how run vector search queries with RediSearch. In this section, we will show how to combine vector search with other RediSearch fields for hybrid search. In the below example, we will combine vector search with full text search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c94d5cce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T00:06:43.261822Z",
     "iopub.status.busy": "2025-10-29T00:06:43.261732Z",
     "iopub.status.idle": "2025-10-29T00:06:43.263537Z",
     "shell.execute_reply": "2025-10-29T00:06:43.263330Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_hybrid_field(field_name: str, value: str) -> str:\n",
    "    return f'@{field_name}:\"{value}\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfcd31c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T00:06:43.264586Z",
     "iopub.status.busy": "2025-10-29T00:06:43.264502Z",
     "iopub.status.idle": "2025-10-29T00:06:43.280421Z",
     "shell.execute_reply": "2025-10-29T00:06:43.280104Z"
    }
   },
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# search the content vector for articles about famous battles in Scottish history and only include results with Scottish in the title\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msearch_redis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mredis_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFamous battles in Scottish history\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mvector_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitle_vector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mhybrid_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_hybrid_field\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mScottish\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                       \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m, in \u001b[0;36msearch_redis\u001b[0;34m(redis_client, user_query, index_name, vector_field, return_fields, hybrid_fields, k)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch_redis\u001b[39m(\n\u001b[1;32m      2\u001b[0m     redis_client: redis\u001b[38;5;241m.\u001b[39mRedis,\n\u001b[1;32m      3\u001b[0m     user_query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Creates embedding vector from user query\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     embedded_query \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEMBEDDING_MODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Prepare the Query\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     base_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhybrid_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=>[KNN \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m @\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvector_field\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m $vector AS vector_score]\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "# search the content vector for articles about famous battles in Scottish history and only include results with Scottish in the title\n",
    "results = search_redis(redis_client,\n",
    "                       \"Famous battles in Scottish history\",\n",
    "                       vector_field=\"title_vector\",\n",
    "                       k=5,\n",
    "                       hybrid_fields=create_hybrid_field(\"title\", \"Scottish\")\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28ab1e30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T00:06:43.281711Z",
     "iopub.status.busy": "2025-10-29T00:06:43.281616Z",
     "iopub.status.idle": "2025-10-29T00:06:43.296228Z",
     "shell.execute_reply": "2025-10-29T00:06:43.295986Z"
    }
   },
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# run a hybrid query for articles about Art in the title vector and only include results with the phrase \"Leonardo da Vinci\" in the text\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msearch_redis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mredis_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mArt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mvector_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitle_vector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mhybrid_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_hybrid_field\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLeonardo da Vinci\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                       \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# find specific mention of Leonardo da Vinci in the text that our full-text-search query returned\u001b[39;00m\n\u001b[1;32m     10\u001b[0m mention \u001b[38;5;241m=\u001b[39m [sentence \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLeonardo da Vinci\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sentence][\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m, in \u001b[0;36msearch_redis\u001b[0;34m(redis_client, user_query, index_name, vector_field, return_fields, hybrid_fields, k)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch_redis\u001b[39m(\n\u001b[1;32m      2\u001b[0m     redis_client: redis\u001b[38;5;241m.\u001b[39mRedis,\n\u001b[1;32m      3\u001b[0m     user_query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Creates embedding vector from user query\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     embedded_query \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEMBEDDING_MODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Prepare the Query\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     base_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhybrid_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=>[KNN \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m @\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvector_field\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m $vector AS vector_score]\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "# run a hybrid query for articles about Art in the title vector and only include results with the phrase \"Leonardo da Vinci\" in the text\n",
    "results = search_redis(redis_client,\n",
    "                       \"Art\",\n",
    "                       vector_field=\"title_vector\",\n",
    "                       k=5,\n",
    "                       hybrid_fields=create_hybrid_field(\"text\", \"Leonardo da Vinci\")\n",
    "                       )\n",
    "\n",
    "# find specific mention of Leonardo da Vinci in the text that our full-text-search query returned\n",
    "mention = [sentence for sentence in results[0].text.split(\"\\n\") if \"Leonardo da Vinci\" in sentence][0]\n",
    "mention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b5be2",
   "metadata": {},
   "source": [
    "For more example with Redis as a vector database, see the README and examples within the ``vector_databases/redis`` directory of this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0119d87a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (redis-vector-db)",
   "language": "python",
   "name": "redis-vector-db"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd16a328ca3d68029457069b79cb0b38eb39a0f5ccc4fe4473d3047707df8207"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}